/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    pgscatalog/pgsc_calc Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/

// Global default params, used in configs
params {
    // runtime params
    platform                   = "amd64"
    parallel                   = false

    // Input params
    input                      = null
    format                     = "csv"
    scorefile                  = null
    pgs_id                     = null
    trait_efo                  = null
    pgp_id                     = null
    efo_direct                 = false

    // reference params
    run_ancestry = null // path to reference database TODO: replace with NO_FILE
    ancestry_checksums = "$projectDir/assets/ancestry/checksums.txt"
    // if you want to liftover --scorefiles, set the chain files
    hg19_chain = null // "https://hgdownload.cse.ucsc.edu/goldenpath/hg19/liftOver/hg19ToHg38.over.chain.gz"
    hg38_chain = null // "https://hgdownload.soe.ucsc.edu/goldenPath/hg38/liftOver/hg38ToHg19.over.chain.gz"
    load_afreq = true
    geno_ref = 0.1
    mind_ref = 0.1
    maf_ref = 0.05
    hwe_ref = 0.0001
    indep_pairwise_ref = "1000 50 0.05"
    ld_grch37 = "$projectDir/assets/ancestry/high-LD-regions-hg19-GRCh37.txt"
    ld_grch38 = "$projectDir/assets/ancestry/high-LD-regions-hg38-GRCh38.txt"

    // ancestry params
    ref_format_version = "v0.1"
    ref_samplesheet = "$projectDir/assets/ancestry/reference.csv"
    projection_method = "oadp"
    ancestry_method = "RandomForest"
    ref_label = "SuperPop"
    n_popcomp = 5
    normalization_method = "empirical mean mean+var"
    n_normalization = 4

    // compatibility params
    liftover = false
    target_build = null
    min_lift = 0.95

    // match params
    min_overlap = 0.75
    keep_ambiguous = false
    keep_multiallelic = false
    fast_match = false
    copy_genomes = false
    genotypes_cache = null

    // Debug params
    only_bootstrap = false
    only_input = false
    only_compatible = false
    only_match = false
    only_projection = false
    only_score = false
    skip_ancestry = true

    // Boilerplate options
    outdir                     = "./results"
    tracedir                   = "${params.outdir}/pipeline_info"
    publish_dir_mode           = 'copy'
    email                      = null
    email_on_fail              = null
    plaintext_email            = false
    monochrome_logs            = false
    help                       = false
    validate_params            = true
    show_hidden_params         = false
    schema_ignore_params       = 'only_bootstrap,only_input,only_compatible,only_match,only_projection,only_score,skip_ancestry'

    // Max resource options
    // Defaults only, expecting to be overwritten
    max_memory                 = '16.GB'
    max_cpus                   = 2
    max_time                   = '240.h'

}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

profiles {
    debug {
        dumpHashes             = true
        process.beforeScript   = 'echo $HOSTNAME'
        cleanup                = false
    }
    conda {
        conda.enabled          = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    mamba {
        conda.enabled          = true
        conda.useMamba         = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    docker {
        def platform = params.platform == 'arm64' ? '--platform linux/arm64' : '--platform linux/amd64'
        docker.runOptions      = ['-u $(id -u):$(id -g) ', platform].join(' ')
        docker.enabled         = true
        docker.userEmulation   = true
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    podman {
        podman.enabled         = true
        docker.enabled         = false
        singularity.enabled    = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    shifter {
        shifter.enabled        = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        charliecloud.enabled   = false
    }
    charliecloud {
        charliecloud.enabled   = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
    }
    gitpod {
        executor.name          = 'local'
        executor.cpus          = 16
        executor.memory        = 60.GB
    }
    test      { includeConfig 'conf/test.config'      }
    test_json { includeConfig 'conf/test_json.config' }
    test_full { includeConfig 'conf/test_full.config' }
}

if (!params.parallel) {
    includeConfig 'conf/sequential.config'
}

// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.tracedir}/pipeline_dag_${trace_timestamp}.html"
}

manifest {
    name            = 'pgscatalog/pgsc_calc'
    author          = 'Samuel Lambert, Benjamin Wingfield'
    defaultBranch   = 'main'
    homePage        = 'http://140.82.113.3/wangmingcheng/pgsc_calc'
    description     = 'The Polygenic Score Catalog Calculator is a nextflow pipeline for polygenic score calculation'
    mainScript      = 'main.nf'
    nextflowVersion = '>=22.10.0'
    version         = '2.0.0-alpha.4'
}

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
